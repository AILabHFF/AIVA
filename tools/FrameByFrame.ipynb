{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-supervised learning of meteor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set csv path of cam data\n",
    "base_path = '/mnt/disk1/KILabDaten/Geminiden2021'\n",
    "\n",
    "csv1_path = base_path + '/kam1.csv'\n",
    "csv2_path = base_path + '/kam2.csv'\n",
    "\n",
    "# Set path of cam data\n",
    "path_c1 = base_path + \"/Kamera1\"\n",
    "path_c2 = base_path + \"/Kamera2\"\n",
    "fileend = '.mov'\n",
    "\n",
    "# Set path of meteor frames\n",
    "meteor_frames_path_c1 = path_c1 + \"/MeteorFrames/\"\n",
    "meteor_frames_path_c2 = path_c2 + \"/MeteorFrames/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cam (1 or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0c87191534484cb3302789c7a9cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Cam Number:', index=1, options=('1', '2'), value='2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropdown widget for cam1 and cam2\n",
    "w = widgets.Dropdown(\n",
    "    options=['1', '2'],\n",
    "    value='2',\n",
    "    description='Cam Number:',\n",
    "    disabled=False,\n",
    "    )\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam 2 selected\n",
      "Folders with wrong number of frames: \n",
      "/mnt/disk1/KILabDaten/Geminiden2021/Kamera2/MeteorFrames//63 209\n",
      "/mnt/disk1/KILabDaten/Geminiden2021/Kamera2/MeteorFrames//526 125\n"
     ]
    }
   ],
   "source": [
    "camdict = {'1':[csv1_path, path_c1, meteor_frames_path_c1], '2':[csv2_path, path_c2, meteor_frames_path_c2]}\n",
    "# Set paths for selected cam\n",
    "\n",
    "camnum = w.value\n",
    "file_path = camdict[camnum][1] #path_c1\n",
    "csv_path = camdict[camnum][0] #csv1_path\n",
    "frame_path = camdict[camnum][2] #outpath_c1\n",
    "\n",
    "\n",
    "# Print how many files are in a subfolder of a path\n",
    "path, dirs, files = os.walk(frame_path).__next__()\n",
    "\n",
    "print(\"Cam \" + camnum + \" selected\")\n",
    "print(\"Folders with wrong number of frames: \")\n",
    "for d in dirs:\n",
    "    p, _, f = os.walk(path + '/' +  d).__next__()\n",
    "    if len(f)!= 251:\n",
    "        print(p, len(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_extension_list(string_list):\n",
    "    # Split the extension from the file name\n",
    "    return sorted([int(os.path.splitext(i)[0]) for i in string_list])\n",
    "\n",
    "\n",
    "def sorted_png_list(string_list):\n",
    "    # Split the extension from the file name and sort the list\n",
    "    lsort = split_extension_list(string_list)\n",
    "    return [str(i) + '.png' for i in lsort]\n",
    "\n",
    "def sorted_string_list(string_list):\n",
    "    # input is a list of strings with numbers\n",
    "    # output is a list of strings with numbers sorted\n",
    "    lsort = sorted([int(i) for i in string_list])\n",
    "    return [str(i) for i in lsort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many files are in a subfolder of a path\n",
    "path, dirs, _ = os.walk(frame_path).__next__()\n",
    "\n",
    "dirs = sorted_string_list(dirs)\n",
    "\n",
    "\n",
    "img_d = {}\n",
    "\n",
    "for d in dirs:\n",
    "    # Get the list of files in the folder\n",
    "    _, _, f = os.walk(path + d).__next__()\n",
    "    lsort = sorted([int(os.path.splitext(f1)[0]) for f1 in f])\n",
    "    lsort = [str(i) + '.png' for i in lsort]\n",
    "    img_d[d] = lsort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator for reading in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "        self.n_name = df[y_col['name']].nunique()\n",
    "        self.n_type = df[y_col['type']].nunique()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path, bbox, target_size):\n",
    "    \n",
    "        xmin, ymin, w, h = bbox['x'], bbox['y'], bbox['width'], bbox['height']\n",
    "\n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = image_arr[ymin:ymin+h, xmin:xmin+w]\n",
    "        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr/255.\n",
    "    \n",
    "    def __get_output(self, label, num_classes):\n",
    "        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        bbox_batch = batches[self.X_col['bbox']]\n",
    "        \n",
    "        name_batch = batches[self.y_col['name']]\n",
    "        type_batch = batches[self.y_col['type']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, y, self.input_size) for x, y in zip(path_batch, bbox_batch)])\n",
    "\n",
    "        y0_batch = np.asarray([self.__get_output(y, self.n_name) for y in name_batch])\n",
    "        y1_batch = np.asarray([self.__get_output(y, self.n_type) for y in type_batch])\n",
    "\n",
    "        return X_batch, tuple([y0_batch, y1_batch])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomDataGen(train_df,\n",
    "                         X_col={'path':'filename', 'bbox': 'region_shape_attributes'},\n",
    "                         y_col={'name': 'name', 'type': 'type'},\n",
    "                         batch_size=batch_size, input_size=target_size)\n",
    "\n",
    "valgen = CustomDataGen(val_df,\n",
    "                       X_col={'path':'filename', 'bbox': 'region_shape_attributes'},\n",
    "                       y_col={'name': 'name', 'type': 'type'},\n",
    "                       batch_size=batch_size, input_size=target_size)\n",
    "\n",
    "model.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1620e63d674e1faf6572b058af6cc0117e2ef24753082eef8346dadbaa37285b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
